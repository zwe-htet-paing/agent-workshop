{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f5bd6b",
   "metadata": {},
   "source": [
    "## Setting Up DeepSeek-R1 Locally With Ollama\n",
    "\n",
    "\n",
    "#### Step 1: Install Ollama\n",
    "\n",
    "First, download and install Ollama from the official [website](https://ollama.com/download/linux).\n",
    "\n",
    "#### Step 2: Download and run DeepSeek-R1\n",
    "\n",
    "```bash\n",
    "ollama run deepseek-r1:1.5b\n",
    "```\n",
    "\n",
    "#### Step 3: Running DeepSeek-R1 in the background\n",
    "\n",
    "```bash\n",
    "ollama serve\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Remove models from Ollama\n",
    "\n",
    "```bash\n",
    "ollama ps\n",
    "ollama stop deepseek-r1:1.5b\n",
    "ollama list\n",
    "ollama rm deepseek-r1:1.5b\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df31b4e",
   "metadata": {},
   "source": [
    "### Accessing DeepSeek-R1 via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad31ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\":\"deepseek-r1:1.5b\",\"created_at\":\"2025-09-21T16:11:28.045852638Z\",\"message\":{\"role\":\"assistant\",\"content\":\"\\u003cthink\\u003e\\nFirst, I recognize that calculating 21 multiplied by 21 directly might be a bit challenging. To simplify the process, I'll break down the number into more manageable parts.\\n\\nI'll start by expressing both numbers as (20 + 1). This means 21 is equal to 20 plus 1.\\n\\nNext, I'll apply the distributive property of multiplication over addition:\\n\\n21 * 21 = (20 + 1) * (20 + 1)\\n\\nI'll then expand this product using the distributive law:\\n\\n= 20*20 + 20*1 + 1*20 + 1*1\\n\\nCalculating each term individually:\\n- 20*20 = 400\\n- 20*1 = 20\\n- 1*20 = 20\\n- 1*1 = 1\\n\\nNow, I'll add all these results together:\\n\\n= 400 + 20 + 20 + 1\\n\\nFinally, summing them up gives the final product.\\n\\u003c/think\\u003e\\n\\nTo find \\\\(21 \\\\times 21\\\\), follow these steps:\\n\\n1. **Break Down the Numbers:**\\n   \\n   Express each number as a sum of simpler parts:\\n   \\\\[\\n   21 = 20 + 1\\n   \\\\]\\n\\n2. **Apply the Distributive Property:**\\n   \\n   Use the formula for multiplying two binomials:\\n   \\\\[\\n   (a + b)(c + d) = ac + ad + bc + bd\\n   \\\\]\\n   Applying this to our numbers:\\n   \\\\[\\n   (20 + 1)(20 + 1) = 20 \\\\times 20 + 20 \\\\times 1 + 1 \\\\times 20 + 1 \\\\times 1\\n   \\\\]\\n\\n3. **Calculate Each Term:**\\n   \\n   - \\\\(20 \\\\times 20 = 400\\\\)\\n   - \\\\(20 \\\\times 1 = 20\\\\)\\n   - \\\\(1 \\\\times 20 = 20\\\\)\\n   - \\\\(1 \\\\times 1 = 1\\\\)\\n\\n4. **Sum the Results:**\\n   \\n   Add all the individual products:\\n   \\\\[\\n   400 + 20 + 20 + 1 = 441\\n   \\\\]\\n\\n**Final Answer:**\\n\\\\[\\n\\\\boxed{441}\\n\\\\]\"},\"done\":true,\"done_reason\":\"stop\",\"total_duration\":20131156844,\"load_duration\":206239699,\"prompt_eval_count\":12,\"prompt_eval_duration\":24025225,\"eval_count\":524,\"eval_duration\":19899812839}"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:11434/api/chat -d '{ \\\n",
    "  \"model\": \"deepseek-r1:1.5b\", \\\n",
    "  \"messages\": [{ \"role\": \"user\", \"content\": \"What is 21 * 21\" }], \\\n",
    "  \"stream\": false \\\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31face",
   "metadata": {},
   "source": [
    "### Accessing DeepSeek-R1 via Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cc04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921277b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e6b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">think</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Okay, I need to explain Ollama briefly. Let's see what I remember about it.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Ollama is an AI platform that uses a genetic algorithm. That means it evolves models by tweaking parameters and </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">measuring performance. It works on the cloud, so you can use it from any device with internet access.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">It's built in Python, which makes it easy to develop and understand. The command-line interface lets users set up </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">models without writing complex code. They can run experiments manually or let Ollama handle them for them.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Applications include text classification, spam detection, and predicting house prices. It helps find the best model</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">quickly by testing different configurations and parameters on datasets.</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">So putting it all together: Ollama is a cloud-based AI tool that evolves models using genetic algorithms, works </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">from any device, is easy to set up without code, supports various tasks like text classification, and runs </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">experiments either manually or automatically.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">think</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "\n",
       "Ollama is an AI platform that uses a genetic algorithm to evolve machine learning models. It operates on the cloud,\n",
       "allowing users to access AI tools from any device with internet connectivity. Built in Python, Ollama provides a \n",
       "command-line interface for setting up models without writing complex code and supports various applications such as\n",
       "text classification, spam detection, and predicting house prices.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mthink\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39mOkay, I need to explain Ollama briefly. Let's see what I remember about it.\u001b[0m\n",
       "\n",
       "\u001b[39mOllama is an AI platform that uses a genetic algorithm. That means it evolves models by tweaking parameters and \u001b[0m\n",
       "\u001b[39mmeasuring performance. It works on the cloud, so you can use it from any device with internet access.\u001b[0m\n",
       "\n",
       "\u001b[39mIt's built in Python, which makes it easy to develop and understand. The command-line interface lets users set up \u001b[0m\n",
       "\u001b[39mmodels without writing complex code. They can run experiments manually or let Ollama handle them for them.\u001b[0m\n",
       "\n",
       "\u001b[39mApplications include text classification, spam detection, and predicting house prices. It helps find the best model\u001b[0m\n",
       "\u001b[39mquickly by testing different configurations and parameters on datasets.\u001b[0m\n",
       "\n",
       "\u001b[39mSo putting it all together: Ollama is a cloud-based AI tool that evolves models using genetic algorithms, works \u001b[0m\n",
       "\u001b[39mfrom any device, is easy to set up without code, supports various tasks like text classification, and runs \u001b[0m\n",
       "\u001b[39mexperiments either manually or automatically.\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mthink\u001b[0m\u001b[1m>\u001b[0m\n",
       "\n",
       "Ollama is an AI platform that uses a genetic algorithm to evolve machine learning models. It operates on the cloud,\n",
       "allowing users to access AI tools from any device with internet connectivity. Built in Python, Ollama provides a \n",
       "command-line interface for setting up models without writing complex code and supports various applications such as\n",
       "text classification, spam detection, and predicting house prices.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model = \"deepseek-r1:1.5b\",\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Explain Ollama in a brief.\"}\n",
    "        ],\n",
    "    stream = False\n",
    ")\n",
    "\n",
    "rich.print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60d905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ollama is an AI platform that uses a genetic algorithm to evolve machine learning models. It operates on the cloud,\n",
       "allowing users to access AI tools from any device with internet connectivity. Built in Python, Ollama provides a \n",
       "command-line interface for setting up models without writing complex code and supports various applications such as\n",
       "text classification, spam detection, and predicting house prices.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ollama is an AI platform that uses a genetic algorithm to evolve machine learning models. It operates on the cloud,\n",
       "allowing users to access AI tools from any device with internet connectivity. Built in Python, Ollama provides a \n",
       "command-line interface for setting up models without writing complex code and supports various applications such as\n",
       "text classification, spam detection, and predicting house prices.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "response_content = response[\"message\"][\"content\"]\n",
    "final_answer = re.sub(r\"<think>.*?</think>\", \"\", response_content, flags=re.DOTALL).strip()\n",
    "\n",
    "rich.print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d659f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">DeepSeek-R1 is an advanced artificial intelligence developed by DeepSeek. It excels in various tasks such as \n",
       "natural language processing, question answering, and scientific research.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "DeepSeek-R1 is an advanced artificial intelligence developed by DeepSeek. It excels in various tasks such as \n",
       "natural language processing, question answering, and scientific research.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ollama_chat(question: str, model: str = \"deepseek-r1:1.5b\") -> str:\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "    )\n",
    "    response_content = response[\"message\"][\"content\"]\n",
    "    final_answer = re.sub(r\"<think>.*?</think>\", \"\", response_content, flags=re.DOTALL).strip()\n",
    "    return final_answer\n",
    "\n",
    "\n",
    "response = ollama_chat(\"Explain DeepSeek-R1 in a brief.\")\n",
    "rich.print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c85b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
